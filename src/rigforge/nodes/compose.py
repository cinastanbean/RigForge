"""
å›å¤ç»„è£…èŠ‚ç‚¹ - Reply Composition Node

ç»„è£…è‡ªç„¶è¯­è¨€å›å¤ï¼ŒåŒ…æ‹¬è¿½é—®å›å¤å’Œæ¨èå›å¤ã€‚
Assemble natural language replies, including follow-up replies and recommendation replies.
"""

from __future__ import annotations

from typing import List, Optional, TYPE_CHECKING

if TYPE_CHECKING:
    from langchain_openai import ChatOpenAI
    from ..data.models import BuildPlan, UserRequirements


def compose_reply(
    build: Optional["BuildPlan"],
    requirements: "UserRequirements",
    issues: List[str],
    llm: Optional["ChatOpenAI"] = None,
    enthusiasm_level: str = "standard",
) -> str:
    """
    ç»„è£…å›å¤ - Compose Reply
    
    æ ¹æ®é…ç½®æ–¹æ¡ˆå’Œç”¨æˆ·éœ€æ±‚ï¼Œç»„è£…è‡ªç„¶è¯­è¨€å›å¤ã€‚
    Assemble natural language reply based on build plan and user requirements.
    
    å‚æ•° Parameters:
        build: é…ç½®æ–¹æ¡ˆï¼ˆå¯èƒ½ä¸º Noneï¼‰
               Build plan (may be None)
        requirements: ç”¨æˆ·éœ€æ±‚
                     User requirements
        issues: å…¼å®¹æ€§é—®é¢˜åˆ—è¡¨
                 List of compatibility issues
        llm: LLM å®ä¾‹ï¼ˆå¯é€‰ï¼‰
             LLM instance (optional)
        enthusiasm_level: çƒ­æƒ…ç¨‹åº¦
                           Enthusiasm level (standard/high)
    
    è¿”å› Returns:
        å›å¤æ–‡æœ¬
        Reply text
    """
    if build is None:
        # è¿½é—®åœºæ™¯ - Follow-up scenario
        return compose_followup_reply(requirements, llm, enthusiasm_level)
    else:
        # æ¨èåœºæ™¯ - Recommendation scenario
        return compose_recommendation_reply(build, requirements, issues, llm, enthusiasm_level)


def compose_followup_reply(
    requirements: "UserRequirements",
    llm: Optional["ChatOpenAI"],
    enthusiasm_level: str,
) -> str:
    """
    ç»„è£…è¿½é—®å›å¤ - Compose Follow-up Reply
    
    æ ¹æ®ç¼ºå¤±çš„éœ€æ±‚ä¿¡æ¯ï¼Œç”Ÿæˆè¿½é—®å›å¤ã€‚
    Generate follow-up reply based on missing requirement information.
    
    å‚æ•° Parameters:
        requirements: ç”¨æˆ·éœ€æ±‚
                     User requirements
        llm: LLM å®ä¾‹ï¼ˆå¯é€‰ï¼‰
             LLM instance (optional)
        enthusiasm_level: çƒ­æƒ…ç¨‹åº¦
                           Enthusiasm level
    
    è¿”å› Returns:
        è¿½é—®å›å¤æ–‡æœ¬
        Follow-up reply text
    """
    # ç®€å•çš„æ¨¡æ¿å›å¤ - Simple template reply
    prefix = "å¤ªæ£’äº†ï¼" if enthusiasm_level == "high" else "æ”¶åˆ°ï¼Œ"
    
    # æ£€æŸ¥ç¼ºå¤±çš„ä¿¡æ¯ - Check missing information
    missing = []
    if requirements.budget_max is None:
        missing.append("é¢„ç®—")
    if requirements.use_case is None:
        missing.append("ç”¨é€”")
    if requirements.resolution is None:
        missing.append("åˆ†è¾¨ç‡")
    
    # æ ¹æ®ç¼ºå¤±ä¿¡æ¯ç”Ÿæˆè¿½é—® - Generate follow-up based on missing information
    if missing:
        return f"{prefix}è¯·é—®æ‚¨çš„{missing[0]}æ˜¯å¤šå°‘å‘¢ï¼Ÿ"
    else:
        return f"{prefix}ä¿¡æ¯å·²æ”¶é›†å®Œæ¯•ï¼Œæ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆé…ç½®æ–¹æ¡ˆ..."


def compose_recommendation_reply(
    build: "BuildPlan",
    requirements: "UserRequirements",
    issues: List[str],
    llm: Optional["ChatOpenAI"],
    enthusiasm_level: str,
) -> str:
    """
    ç»„è£…æ¨èå›å¤ - Compose Recommendation Reply
    
    æ ¹æ®é…ç½®æ–¹æ¡ˆå’Œå…¼å®¹æ€§é—®é¢˜ï¼Œç”Ÿæˆæ¨èå›å¤ã€‚
    Generate recommendation reply based on build plan and compatibility issues.
    
    å‚æ•° Parameters:
        build: é…ç½®æ–¹æ¡ˆ
               Build plan
        requirements: ç”¨æˆ·éœ€æ±‚
                     User requirements
        issues: å…¼å®¹æ€§é—®é¢˜åˆ—è¡¨
                 List of compatibility issues
        llm: LLM å®ä¾‹ï¼ˆå¯é€‰ï¼‰
             LLM instance (optional)
        enthusiasm_level: çƒ­æƒ…ç¨‹åº¦
                           Enthusiasm level
    
    è¿”å› Returns:
        æ¨èå›å¤æ–‡æœ¬
        Recommendation reply text
    """
    lines = []
    
    # å¼€åœº - Opening
    if enthusiasm_level == "high":
        lines.append("å¤ªæ£’äº†ï¼ä¸ºæ‚¨æ‰¾åˆ°äº†ä¸€å¥—å¾ˆæ£’çš„é…ç½®ï¼")
    else:
        lines.append("æ ¹æ®æ‚¨çš„éœ€æ±‚ï¼Œæ¨èä»¥ä¸‹é…ç½®ï¼š")
    
    # é…ç½®æ¸…å• - Build list
    lines.append("")
    if build.cpu:
        lines.append(f"ğŸ–¥ï¸ CPU: {build.cpu.name} - Â¥{build.cpu.price}")
    if build.motherboard:
        lines.append(f"ğŸ”§ ä¸»æ¿: {build.motherboard.name} - Â¥{build.motherboard.price}")
    if build.memory:
        lines.append(f"ğŸ’¾ å†…å­˜: {build.memory.name} - Â¥{build.memory.price}")
    if build.gpu:
        lines.append(f"ğŸ® æ˜¾å¡: {build.gpu.name} - Â¥{build.gpu.price}")
    if build.storage:
        lines.append(f"ğŸ’¿ å­˜å‚¨: {build.storage.name} - Â¥{build.storage.price}")
    if build.psu:
        lines.append(f"âš¡ ç”µæº: {build.psu.name} - Â¥{build.psu.price}")
    if build.case:
        lines.append(f"ğŸ“¦ æœºç®±: {build.case.name} - Â¥{build.case.price}")
    if build.cooler:
        lines.append(f"â„ï¸ æ•£çƒ­: {build.cooler.name} - Â¥{build.cooler.price}")
    
    # æ€»ä»· - Total price
    lines.append(f"\nğŸ’° æ€»ä»·: Â¥{build.total_price()}")
    
    # å…¼å®¹æ€§é—®é¢˜ - Compatibility issues
    if issues:
        lines.append("\nâš ï¸ æ³¨æ„äº‹é¡¹ï¼š")
        for issue in issues:
            lines.append(f"  - {issue}")
    
    return "\n".join(lines)


def compose_reply_node(state: dict) -> dict:
    """
    å›å¤ç»„è£…èŠ‚ç‚¹å…¥å£å‡½æ•° - Reply Composition Node Entry Function
    
    æ­¤å‡½æ•°å°†è¢« graph.py è°ƒç”¨ã€‚
    This function will be called by graph.py.
    
    å‚æ•° Parameters:
        state: å½“å‰çŠ¶æ€å­—å…¸
               Current state dictionary
    
    è¿”å› Returns:
        æ›´æ–°åçš„çŠ¶æ€å­—å…¸ï¼ŒåŒ…å«å›å¤æ–‡æœ¬
        Updated state dictionary containing reply text
    """
    build = state.get("build")
    requirements = state.get("requirements")
    issues = state.get("compatibility_issues", [])
    llm = state.get("llm")
    enthusiasm_level = state.get("enthusiasm_level", "standard")
    
    reply = compose_reply(build, requirements, issues, llm, enthusiasm_level)
    
    return {"response_text": reply}
